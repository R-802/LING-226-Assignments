{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMsUrwFqjTUrEjvHQekqUPO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/R-802/LING-226-Assignments/blob/main/Assignment_One.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Shemaiah Rangitaawa Assignment One LING226 2023 T3 `300601546`**\n",
        "- Attempting Challenge"
      ],
      "metadata": {
        "id": "tDF9NZcFWpFx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Text Preprocessing `preprocess_text`**\n",
        "**Remove Punctuation**\n",
        "- The function strips all punctuation from the text.\n",
        "\n",
        "**Remove Stopwords**\n",
        "- Stopwords, like \"the\", \"is\", \"at\" are removed from the text.\n",
        "\n",
        "**Lowercase All Words**\n",
        "- The text is converted to lowercase. This standardization is important as it prevents the same words in different cases from being counted as different words (e.g., \"Hello\" and \"hello\").\n",
        "\n",
        "**Remove Words Above a Certain Frequency (Inclusive)**\n",
        "- Words that appear very rarely or very frequently in the dataset can be removed. Rare words might be typos or irrelevant, and very common words might not carry useful information.\n"
      ],
      "metadata": {
        "id": "PXj8RZ3HXJnX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "CyQLnGe6WdNB"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "def preprocess_text(text, stopwords, removal_frequency):\n",
        "    # Initialize the lemmatizer\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "    # Lowercase and remove punctuation\n",
        "    text = re.sub(r'[^\\w\\s]', '', text).lower()\n",
        "\n",
        "    # Split text into words\n",
        "    words = text.split()\n",
        "\n",
        "    # Count the frequency of each word\n",
        "    word_frequency = Counter(words)\n",
        "\n",
        "    # Identify words to remove: stopwords and words exceeding the frequency threshold\n",
        "    removed_words = set(stopwords).union(\n",
        "        {word for word, freq in word_frequency.items() if freq >= removal_frequency}\n",
        "    )\n",
        "\n",
        "    # Filter out removed words\n",
        "    processed_words = [word for word in words if word not in removed_words]\n",
        "\n",
        "    return ' '.join(processed_words), list(removed_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Text Metric Function `text_metrics`**\n",
        "**Total Words:** The total count of words in the text.\n",
        "\n",
        "**Overall Lexical Diversity:** The ratio of unique words to the total number of words, providing a measure of the text's vocabulary variety.\n",
        "\n",
        "**Average Sentence Lexical Diversity:** The average diversity of vocabulary used across all sentences in the text.\n",
        "\n",
        "**Top Ten Most Frequent Word:** A list of the ten most commonly used words in the text, along with their frequencies.\n",
        "\n",
        "**Total Number of Sentences:** The total sentence count of the text. When analysing processed text, this metric becomes redundant as there is no punctuation to split the text on."
      ],
      "metadata": {
        "id": "3vUGCuRUgnEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def text_metrics(text):\n",
        "    # Tokenizing the text into words\n",
        "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
        "    total_words = len(words)\n",
        "\n",
        "    # Overall lexical diversity (unique words / total words)\n",
        "    unique_words = len(set(words))\n",
        "    overall_lexical_diversity = unique_words / total_words if total_words > 0 else 0\n",
        "\n",
        "    # Tokenizing the text into sentences and calculating diversity\n",
        "    sentences = re.split(r'[.!?]', text)\n",
        "    sentence_diversities = []\n",
        "    for sentence in sentences:\n",
        "        sentence_words = re.findall(r'\\b\\w+\\b', sentence.lower())\n",
        "        unique_in_sentence = len(set(sentence_words))\n",
        "        total_in_sentence = len(sentence_words)\n",
        "        if total_in_sentence > 0:\n",
        "            sentence_diversities.append(unique_in_sentence / total_in_sentence)\n",
        "\n",
        "    # Average lexical diversity of text sentences\n",
        "    avg_sentence_lexical_diversity = sum(sentence_diversities) / len(sentence_diversities) if sentence_diversities else 0\n",
        "\n",
        "    # Top ten most frequent words\n",
        "    word_frequencies = Counter(words)\n",
        "    top_ten_words = word_frequencies.most_common(10)\n",
        "\n",
        "    # Number of sentences\n",
        "    num_sentences = len(sentences)\n",
        "\n",
        "    return total_words, overall_lexical_diversity, avg_sentence_lexical_diversity, top_ten_words, num_sentences\n"
      ],
      "metadata": {
        "id": "STuEJkn-4aXC"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Formatting for Text Metrics**"
      ],
      "metadata": {
        "id": "WKvarCUatq2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_metrics(title, metrics):\n",
        "    formatted_top_words = ', '.join([word for word, _ in metrics[3]])\n",
        "    highest_word, highest_freq = metrics[3][0]  # Extracting the highest frequency word and its frequency\n",
        "\n",
        "    # Formatting the diversities as percentages\n",
        "    overall_diversity_percentage = metrics[1] * 100\n",
        "    avg_sentence_diversity_percentage = metrics[2] * 100\n",
        "\n",
        "    return (f\"--------- Text Metrics for {title} ---------\\n\"\n",
        "            f\"Total Words: {metrics[0]}\\n\"\n",
        "            f\"Total Sentences: {metrics[4]}\\n\"\n",
        "            f\"Overall Lexical Diversity: {overall_diversity_percentage:.2f}%\\n\"\n",
        "            f\"Average Lexical Diversity of Sentences: {avg_sentence_diversity_percentage:.2f}%\\n\"\n",
        "            f\"Top Ten Most Frequent Words: {formatted_top_words}\\n\"\n",
        "            f\"Highest Frequency Word: '{highest_word}' (Frequency: {highest_freq})\")\n"
      ],
      "metadata": {
        "id": "1bFtign7tLu9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Importing and Reading `TP001.txt` from URL and `austen-emma.txt` from NLTK corpora**"
      ],
      "metadata": {
        "id": "-Dk5c65Ieyu5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget 'https://raw.githubusercontent.com/scskalicky/LING-226-vuw/main/the-current/tp001.txt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9jh2IuW8ytE",
        "outputId": "ed544343-efed-40ae-9ff7-52dca4415651"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-16 22:49:07--  https://raw.githubusercontent.com/scskalicky/LING-226-vuw/main/the-current/tp001.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 220746 (216K) [text/plain]\n",
            "Saving to: ‘tp001.txt’\n",
            "\n",
            "tp001.txt           100%[===================>] 215.57K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-11-16 22:49:08 (1.77 MB/s) - ‘tp001.txt’ saved [220746/220746]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the file and read its lines\n",
        "with open('tp001.txt', 'r', encoding='utf-8') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "# Concatenate all comments into a single text string\n",
        "tp001_text = \"\"\n",
        "for line in lines:\n",
        "    if '\\t' in line:\n",
        "        comment = line.split('\\t')[1].strip()  # Extract and strip the comment\n",
        "        tp001_text += comment + \" \"  # Add the comment to the text string\n",
        "\n",
        "# Optionally, display the first part of the concatenated text\n",
        "print(\"First part of tp001_text:\", tp001_text[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNn54koW82et",
        "outputId": "cf2b845d-a6f9-4062-a0b8-5425c0bc9467"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First part of tp001_text: ... we need to work hard to make it happen 3d is better than other bands in the whole country a ban on sales of new petrol vehicles would be more sensible than an outright ban .  an outright ban is itself wasteful A carless life is much more fun A good idea in theory but would have to change a lot of infrastructure. Not to mention industry and jobs. a good idea to protect our earth ! A good opportunity to reduce harm to the environment A N G E R Y A s part of many other changes A STEP IN THE RIG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import gutenberg\n",
        "\n",
        "# Download gutenberg corpus\n",
        "nltk.download('gutenberg')\n",
        "\n",
        "# Using Emma by Jane Austen 1816\n",
        "emma_text = gutenberg.raw('austen-emma.txt')\n",
        "print(emma_text[:290])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEbU2LnzDSPT",
        "outputId": "92c61e6e-ade3-436e-ccc8-ee408170de62"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Emma by Jane Austen 1816]\n",
            "\n",
            "VOLUME I\n",
            "\n",
            "CHAPTER I\n",
            "\n",
            "\n",
            "Emma Woodhouse, handsome, clever, and rich, with a comfortable home\n",
            "and happy disposition, seemed to unite some of the best blessings\n",
            "of existence; and had lived nearly twenty-one years in the world\n",
            "with very little to distress or vex her.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Experimentation**\n",
        "The following experimentation section includes:\n",
        "- An analysis and overview of metrics from both sample texts.  \n",
        "- Visualization of the top ten words before and after processing.\n",
        "- Analysis of Emma's overall lexical diversity before and after processing.\n",
        "\n",
        "**Notes:** I have chosen to use the NLTK's stopword list for preprocessing. I  have used 'Emma by Jane Austen 1816' from NLTK corpora and 'TP001 (Petrol cars should be banned by 2030)' from The Current."
      ],
      "metadata": {
        "id": "_xjsTV0Ri3hI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Importing libraries and initializing stopwords set**\n",
        "Required for preprocessing and visualization."
      ],
      "metadata": {
        "id": "sbO_HHU0R2iV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "# Tokenizer divides a text into a list of sentences\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Download the stopwords from NLTK\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Create a set of English stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# For some reason 'n' was the top word in tp001\n",
        "stop_words.add('n')\n",
        "\n",
        "print(stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4juI6hyjoikN",
        "outputId": "7bd9621f-8869-4c74-bd58-5de0fb11335d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'him', 'through', 'any', 'down', 'just', 'in', 'both', 'no', 'mightn', 'yourself', 'yourselves', 'against', 'above', 'needn', 'how', \"should've\", 'too', 'over', 'shouldn', 'for', 'n', 'but', 'd', \"hasn't\", 'theirs', 'weren', \"don't\", 'haven', \"mightn't\", \"needn't\", 've', 'same', 'm', \"mustn't\", 'being', 'once', 'there', 'were', 'of', 'was', 'did', 'are', 'why', \"wasn't\", 'mustn', 'while', 'to', 'so', 'if', 'off', 'wasn', 'who', 'themselves', 'them', 'out', \"hadn't\", 'she', 'won', 'be', 'do', 'his', 's', \"isn't\", 'don', 'didn', 'we', \"aren't\", 'all', 'these', \"doesn't\", 'our', 'on', 'her', 'has', 'hers', 'is', 'some', 'only', 'hasn', 'again', 'until', 'ourselves', 'should', 'here', 'i', 'which', 'itself', 'after', 'had', 'those', \"couldn't\", 'now', 'can', 'further', \"weren't\", 't', 'into', 'wouldn', 'the', 'ma', 'between', \"you've\", 'more', 'each', \"that'll\", 'y', \"shan't\", 'doing', 'ours', 'when', 'herself', 'isn', 'yours', 'below', 're', 'very', 'with', 'not', 'by', 'doesn', 'will', \"wouldn't\", 'own', \"didn't\", 'aren', 'as', 'up', 'other', 'does', 'under', \"won't\", \"it's\", 'what', 'hadn', 'about', 'most', \"she's\", \"haven't\", 'at', 'then', 'have', 'shan', 'its', 'nor', \"shouldn't\", 'before', 'couldn', 'this', 'you', 'he', 'and', 'that', 'their', 'whom', 'than', 'they', 'your', 'it', 'where', 'or', 'am', 'ain', 'a', 'an', 'during', \"you're\", 'my', 'having', 'o', 'because', 'me', 'been', 'such', \"you'll\", 'few', 'll', 'from', \"you'd\", 'himself', 'myself'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Analysis and overview of metrics from both sample texts**\n",
        "\n",
        "### Text Metrics for \"Emma\" by Jane Austen\n",
        "#### Unprocessed Text\n",
        "\n",
        "- **Total Words:** `161,983`\n",
        "  \n",
        "  Indicates the substantial length typical of 19th-century novels.\n",
        "\n",
        "- **Total Sentences:** `10,567`\n",
        "\n",
        "- **Overall Lexical Diversity:** `4.48%`\n",
        "\n",
        "  A relatively small proportion of unique words, common in longer texts with repetitive usage of certain words.\n",
        "\n",
        "- **Average Lexical Diversity of Sentences:** `94.43%`\n",
        "\n",
        "  Most sentences contain a high proportion of unique words, suggesting varied sentence structures and vocabulary.\n",
        "\n",
        "- **Top Ten Most Frequent Words:** `to, the, and, of, i, a, it, her, was, she`\n",
        "\n",
        "  Common in unprocessed English texts, indicating frequent use of linguistic connectors and pronouns.\n",
        "\n",
        "- **Highest Frequency Word:** `'to'` (Frequency: `5,239`)\n",
        "\n",
        "  Highlights its prevalent role in sentence construction.\n",
        "\n",
        "#### Processed Text\n",
        "\n",
        "- **Total Words:** `56,909`\n",
        "\n",
        "  Significantly lower, likely due to the removal of common words and other processing steps.\n",
        "\n",
        "- **Total Sentences:** `1`\n",
        "\n",
        "  This is an artifact of how `text_metrics` processes text.\n",
        "- **Overall Lexical Diversity:**\n",
        "\n",
        "  Typically higher than the unprocessed text, suggesting a greater variety of unique words after removing common ones.\n",
        "\n",
        "- **Top Ten Most Frequent Words:** `frank, ever, young, churchill, two, though, indeed, better, come, oh`\n",
        "  \n",
        "  More specific and thematic, focusing on characters and narrative elements.\n",
        "\n",
        "- **Highest Frequency Word:** `'frank'` (Frequency: `192`)\n",
        "  \n",
        "  Indicates a shift towards content-specific vocabulary.\n",
        "\n",
        "#### Insights and Implications\n",
        "\n",
        "- **Impact of Processing:** The processing significantly alters the text's word count and frequency distribution, emphasizing content-specific words.\n",
        "\n",
        "- **Narrative Focus:** The shift in frequent words from common linguistic elements to character names and thematic words reflects the novel's narrative focus.\n",
        "\n",
        "- **Lexical Diversity:** The increase in lexical diversity in the processed text highlights the contribution of unique, content-specific words to the richness of vocabulary, as opposed to common structural words.\n",
        "\n",
        "---\n",
        "\n",
        "## Text Metrics Analysis for `tp001`\n",
        "\n",
        "#### Unprocessed Text\n",
        "\n",
        "- **Total Words:** `39,065`\n",
        "- **Total Sentences:** `2,037`\n",
        "- **Overall Lexical Diversity:** `12.06%`\n",
        "\n",
        "  Shows a reasonable variety of vocabulary.\n",
        "\n",
        "- **Average Lexical Diversity of Sentences:** `89.43%`\n",
        "\n",
        "  Most sentences have a high proportion of unique words, indicating diverse sentence construction.\n",
        "\n",
        "- **Top Ten Most Frequent Words:** `the, to, we, and, i, it, a, is, be, for`\n",
        "\n",
        "  Typical of unprocessed English texts, these are common structural words.\n",
        "\n",
        "- **Highest Frequency Word:** `'the'` (Frequency: `1,507`)\n",
        "\n",
        "  Common in English texts, often used for grammatical structure.\n",
        "\n",
        "#### Processed Text\n",
        "\n",
        "- **Total Words:** `18,059`\n",
        "\n",
        "  Significantly reduced, likely due to the removal of common words and possibly other processing steps.\n",
        "\n",
        "- **Overall Lexical Diversity:** `25.80%`\n",
        "\n",
        "  A noticeable increase from the unprocessed text, indicating a higher proportion of unique words after processing.\n",
        "\n",
        "- **Top Ten Most Frequent Words:** `environment, future, would, people, bad, world, make, dont, transport, climate`\n",
        "\n",
        "  These words reveal the main focus of the text.\n",
        "\n",
        "- **Highest Frequency Word:** `'environment'` (Frequency: `189`)\n",
        "\n",
        "  Indicates a strong emphasis on environmental themes in the text.\n",
        "\n",
        "#### Insights and Implications\n",
        "\n",
        "- **Impact of Processing:** The reduction in total word count and the shift in word frequency distribution underscore the effect of text processing.\n",
        "\n",
        "- **Thematic Focus:** Processing the text highlights specific themes like the environment and future, which are less apparent in the unprocessed text due to the prevalence of common structural words.\n",
        "\n",
        "- **Lexical Diversity:** The increase in lexical diversity post-processing reflects the removal of common words, leaving a text rich in unique, content-specific vocabulary."
      ],
      "metadata": {
        "id": "BBI2_fzUQlXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get text metrics for raw unprocessed text\n",
        "emma_metrics = text_metrics(emma_text)\n",
        "tp001_metrics = text_metrics(tp001_text)\n",
        "\n",
        "# Extracting top ten words and their frequencies for plotting for both texts\n",
        "emma_top_ten_words, emma_frequencies = zip(*emma_metrics[3])\n",
        "tp001_top_ten_words, tp001_frequencies = zip(*tp001_metrics[3])\n",
        "\n",
        "# Extract the number of sentences\n",
        "emma_num_sentences = emma_metrics[4]\n",
        "tp001_num_sentences = tp001_metrics[4]\n",
        "\n",
        "# Generate a random text occurrence removal frequency\n",
        "random_frequency = random.randint(125, 300)\n",
        "\n",
        "# Preprocess the texts\n",
        "preprocessed_emma, _ = preprocess_text(emma_text, stop_words, random_frequency)\n",
        "preprocessed_tp001, _ = preprocess_text(tp001_text, stop_words, random_frequency)\n",
        "\n",
        "# Get metrics for preprocessed texts\n",
        "preprocessed_emma_metrics = text_metrics(preprocessed_emma)\n",
        "preprocessed_tp001_metrics = text_metrics(preprocessed_tp001)\n",
        "\n",
        "# Extracting top ten words and their frequencies for preprocessed texts\n",
        "preprocessed_emma_top_ten, preprocessed_emma_freq = zip(*preprocessed_emma_metrics[3])\n",
        "preprocessed_tp001_top_ten, preprocessed_tp001_freq = zip(*preprocessed_tp001_metrics[3])\n",
        "\n",
        "# Extract the number of sentences for preprocessed texts\n",
        "preprocessed_emma_num_sentences = preprocessed_emma_metrics[4]\n",
        "preprocessed_tp001_num_sentences = preprocessed_tp001_metrics[4]\n",
        "\n",
        "\n",
        "print(format_metrics(\"Emma (Unprocessed)\", emma_metrics) + \"\\n\")\n",
        "print(format_metrics(\"Emma (Processed)\", preprocessed_emma_metrics) + \"\\n\")\n",
        "print(format_metrics(\"tp001.txt (Unprocessed)\", tp001_metrics) + \"\\n\")\n",
        "print(format_metrics(\"tp001.txt (Processed)\", preprocessed_tp001_metrics) + \"\\n\")\n",
        "print(f\"\\nRemoved words that occurred more than {random_frequency} times.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98VOzO9MqP1k",
        "outputId": "10be8f20-1f9c-4e50-f6e9-77520bb62daa"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- Text Metrics for Emma (Unprocessed) ---------\n",
            "Total Words: 161983\n",
            "Total Sentences: 10567\n",
            "Overall Lexical Diversity: 4.48%\n",
            "Average Lexical Diversity of Sentences: 94.43%\n",
            "Top Ten Most Frequent Words: to, the, and, of, i, a, it, her, was, she\n",
            "Highest Frequency Word: 'to' (Frequency: 5239)\n",
            "\n",
            "--------- Text Metrics for Emma (Processed) ---------\n",
            "Total Words: 61193\n",
            "Total Sentences: 1\n",
            "Overall Lexical Diversity: 15.21%\n",
            "Average Lexical Diversity of Sentences: 15.21%\n",
            "Top Ten Most Frequent Words: jane, time, great, woodhouse, nothing, dear, always, soon, may, thought\n",
            "Highest Frequency Word: 'jane' (Frequency: 272)\n",
            "\n",
            "--------- Text Metrics for tp001.txt (Unprocessed) ---------\n",
            "Total Words: 39065\n",
            "Total Sentences: 2037\n",
            "Overall Lexical Diversity: 12.06%\n",
            "Average Lexical Diversity of Sentences: 89.43%\n",
            "Top Ten Most Frequent Words: the, to, we, and, i, it, a, is, be, for\n",
            "Highest Frequency Word: 'the' (Frequency: 1507)\n",
            "\n",
            "--------- Text Metrics for tp001.txt (Processed) ---------\n",
            "Total Words: 19384\n",
            "Total Sentences: 1\n",
            "Overall Lexical Diversity: 24.07%\n",
            "Average Lexical Diversity of Sentences: 24.07%\n",
            "Top Ten Most Frequent Words: think, electric, change, better, good, planet, environment, future, would, people\n",
            "Highest Frequency Word: 'think' (Frequency: 274)\n",
            "\n",
            "\n",
            "Removed words that occurred more than 275 times.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Visualization of The Top Ten Words with Their Frequencies Before and After Processing**\n",
        "\n",
        "The visual comparison of word frequencies before and after text processing illustrates the shift from generic to specific language elements, informing the thematic interpretation of the text.\n",
        "\n",
        "**Before Processing:**\n",
        "The initial charts for \"Emma\" and \"TP001\" show a high frequency of stop words—common elements such as \"to,\" \"the,\" \"and,\" \"of,\" among others, which serve basic grammatical functions but do not distinguish the text's unique content. The analysis highlights the need to eliminate these stop words in preprocessing to pave the way for a more focused examination of the text's themes and subjects.\n",
        "\n",
        "**After Processing:**\n",
        "Upon removing stop words, \"Processed Emma\" displays words that are central to the text's narrative. Terms such as \"dear,\" \"always,\" \"soon,\" \"may,\" \"thought,\" \"see,\" \"shall,\" \"without,\" \"man,\" and \"first\" emerge, which suggest the narrative's focus on personal relationships and internal contemplation. These words carry specific thematic weight, indicating emotions, time, and philosophical considerations that are integral to understanding \"Emma\" by Jane Austen, published in 1816.\n",
        "\n",
        "In the \"TP001\" chart, the removal of stop words brings forward terms such as \"electric,\" \"change,\" \"better,\" \"good,\" \"planet,\" \"environment,\" \"future,\" \"would,\" \"people,\" and \"bad.\" These terms indicate a focus on environmental issues, progress, and evaluative commentary, signaling discussions around ecological responsibility, advancements, and societal impacts.\n",
        "\n",
        "The transition from unprocessed to processed words is crucial in text analysis. By filtering out non-informative words and focusing on content-rich terms, the analysis can more accurately identify the main themes, sentiments, and discussion points within the text. The processing enables extraction of the core topics and narratives, providing a clearer view of the text's intent and subject matter."
      ],
      "metadata": {
        "id": "GfqQ-qJwRFnI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a subplot figure with 2 rows and 2 columns\n",
        "fig = make_subplots(\n",
        "    rows=2, cols=2,\n",
        "    subplot_titles=('Unprocessed Emma', 'Unprocessed TP001', 'Processed Emma', 'Processed TP001')\n",
        ")\n",
        "\n",
        "# Original Emma\n",
        "fig.add_trace(\n",
        "    go.Bar(x=emma_top_ten_words, y=emma_frequencies),\n",
        "    row=1, col=1\n",
        ")\n",
        "\n",
        "# Original TP001\n",
        "fig.add_trace(\n",
        "    go.Bar(x=tp001_top_ten_words, y=tp001_frequencies),\n",
        "    row=1, col=2\n",
        ")\n",
        "\n",
        "# Preprocessed Emma\n",
        "fig.add_trace(\n",
        "    go.Bar(x=preprocessed_emma_top_ten, y=preprocessed_emma_freq),\n",
        "    row=2, col=1\n",
        ")\n",
        "\n",
        "# Preprocessed TP001\n",
        "fig.add_trace(\n",
        "    go.Bar(x=preprocessed_tp001_top_ten, y=preprocessed_tp001_freq),\n",
        "    row=2, col=2\n",
        ")\n",
        "\n",
        "# Update layout\n",
        "fig.update_layout(\n",
        "    title_text='Top Ten Words and Their Frequencies',\n",
        "    showlegend=False,\n",
        "    height=800, width=1200\n",
        ")\n",
        "\n",
        "# Customize axis labels\n",
        "fig.update_xaxes(title_text='Words', row=1, col=1)\n",
        "fig.update_xaxes(title_text='Words', row=1, col=2)\n",
        "fig.update_xaxes(title_text='Words', row=2, col=1)\n",
        "fig.update_xaxes(title_text='Words', row=2, col=2)\n",
        "fig.update_yaxes(title_text='Occurrence Frequency', col=1)\n",
        "\n",
        "# Show the figure\n",
        "fig.show()\n",
        "\n",
        "# Print removed words note\n",
        "print(f\"\\nRemoved words that occur more than {random_frequency} times.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 852
        },
        "id": "8gMxQcxkFv03",
        "outputId": "4ec5a5ee-5c48-474d-92d4-0f1b72ee571a"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"068dda2e-9208-451a-b39c-7aceb2ea5db8\" class=\"plotly-graph-div\" style=\"height:800px; width:1200px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"068dda2e-9208-451a-b39c-7aceb2ea5db8\")) {                    Plotly.newPlot(                        \"068dda2e-9208-451a-b39c-7aceb2ea5db8\",                        [{\"x\":[\"to\",\"the\",\"and\",\"of\",\"i\",\"a\",\"it\",\"her\",\"was\",\"she\"],\"y\":[5239,5201,4896,4291,3178,3129,2528,2469,2398,2340],\"type\":\"bar\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"x\":[\"the\",\"to\",\"we\",\"and\",\"i\",\"it\",\"a\",\"is\",\"be\",\"for\"],\"y\":[1507,1498,986,971,747,730,708,686,663,622],\"type\":\"bar\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"x\":[\"jane\",\"time\",\"great\",\"woodhouse\",\"nothing\",\"dear\",\"always\",\"soon\",\"may\",\"thought\"],\"y\":[272,266,263,262,242,235,234,224,219,218],\"type\":\"bar\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"x\":[\"think\",\"electric\",\"change\",\"better\",\"good\",\"planet\",\"environment\",\"future\",\"would\",\"people\"],\"y\":[274,220,219,207,203,202,189,179,176,156],\"type\":\"bar\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.45],\"title\":{\"text\":\"Words\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.625,1.0],\"title\":{\"text\":\"Occurrence Frequency\"}},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.55,1.0],\"title\":{\"text\":\"Words\"}},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.625,1.0]},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.0,0.45],\"title\":{\"text\":\"Words\"}},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,0.375],\"title\":{\"text\":\"Occurrence Frequency\"}},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.55,1.0],\"title\":{\"text\":\"Words\"}},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.0,0.375]},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Unprocessed Emma\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Unprocessed TP001\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Processed Emma\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Processed TP001\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Top Ten Words and Their Frequencies\"},\"showlegend\":false,\"height\":800,\"width\":1200},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('068dda2e-9208-451a-b39c-7aceb2ea5db8');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Removed words that occur more than 275 times.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Comparative Analysis of Overall Lexical Diversity in Processed and Unprocessed Versions of \"Emma\" by Jane Austen.**\n",
        "\n",
        "The results of the analysis below show the overall lexical diversity of Jane Austen's \"Emma\" in both its processed and unprocessed forms as the batch size (number of sentences per batch) increases.\n",
        "\n",
        "**Processed Overall Lexical Diversity (Blue):** As the batch size increases, we observe a gradual decrease in lexical diversity. This indicates that when analyzing larger portions of the text together, the processed version becomes less lexically diverse.\n",
        "\n",
        "**Unprocessed Overall Lexical Diversity (Red):** This line represents the lexical diversity of the original, unprocessed text. Similarly, as the batch size increases, we also see a decrease in lexical diversity."
      ],
      "metadata": {
        "id": "3CnO9l6vbV9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "increment = 100  # n sentences per increment\n",
        "batch_sizes = list(range(1, emma_num_sentences, increment))  # Incrementally increase batch size\n",
        "\n",
        "overall_lex_div_unprocessed = []\n",
        "overall_lex_div_processed = []\n",
        "\n",
        "# Split the text into sentences\n",
        "sentences = sent_tokenize(emma_text)\n",
        "\n",
        "# Calculate lexical diversities\n",
        "for batch_size in batch_sizes:\n",
        "    # Concatenate all sentences up to the current batch size\n",
        "    concatenated_unprocessed = ' '.join(sentences[:batch_size])\n",
        "    concatenated_processed = preprocess_text(concatenated_unprocessed, stop_words, random_frequency)[0]\n",
        "\n",
        "    # Calculate overall lexical diversity for the concatenated text\n",
        "    overall_lex_div_unprocessed.append(text_metrics(concatenated_unprocessed)[1])\n",
        "    overall_lex_div_processed.append(text_metrics(concatenated_processed)[1])"
      ],
      "metadata": {
        "id": "XrH5B2OcbdOT"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare batch size labels with sentence count\n",
        "batch_size_labels = [batch_size for batch_size in batch_sizes]\n",
        "\n",
        "# Convert lexical diversity to percentages\n",
        "processed_lex_div = [ld * 100 for ld in overall_lex_div_processed]\n",
        "unprocessed_lex_div = [ld * 100 for ld in overall_lex_div_unprocessed]\n",
        "\n",
        "# Create traces\n",
        "trace1 = go.Scatter(\n",
        "    x=batch_size_labels,\n",
        "    y=processed_lex_div,\n",
        "    mode='lines+markers',\n",
        "    name='Overall Lexical Diversity (Processed)',\n",
        ")\n",
        "trace2 = go.Scatter(\n",
        "    x=batch_size_labels,\n",
        "    y=unprocessed_lex_div,\n",
        "    mode='lines+markers',\n",
        "    name='Overall Lexical Diversity (Unprocessed)',\n",
        ")\n",
        "\n",
        "# Layout\n",
        "layout = go.Layout(\n",
        "    title='Overall Lexical Diversity over Batch Size Increments',\n",
        "    xaxis=dict(title='Number of Sentences'),\n",
        "    yaxis=dict(title='Lexical Diversity (%)'),\n",
        ")\n",
        "\n",
        "# Figure\n",
        "fig = go.Figure(data=[trace1, trace2], layout=layout)\n",
        "\n",
        "# Show plot\n",
        "fig.show()\n",
        "\n",
        "# Print metrics (assuming format_metrics is defined)\n",
        "print(\"\\n\" + format_metrics(\"Emma (Unprocessed)\", emma_metrics) + \"\\n\")\n",
        "print(format_metrics(\"Emma (Processed)\", preprocessed_emma_metrics) + \"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 837
        },
        "id": "kncVNwO_y_L3",
        "outputId": "08d11792-3ec4-4c08-aa35-fb5e0183445e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"75217271-a37c-474f-993d-7e48d619c5d6\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"75217271-a37c-474f-993d-7e48d619c5d6\")) {                    Plotly.newPlot(                        \"75217271-a37c-474f-993d-7e48d619c5d6\",                        [{\"mode\":\"lines+markers\",\"name\":\"Overall Lexical Diversity (Processed)\",\"x\":[1,101,201,301,401,501,601,701,801,901,1001,1101,1201,1301,1401,1501,1601,1701,1801,1901,2001,2101,2201,2301,2401,2501,2601,2701,2801,2901,3001,3101,3201,3301,3401,3501,3601,3701,3801,3901,4001,4101,4201,4301,4401,4501,4601,4701,4801,4901,5001,5101,5201,5301,5401,5501,5601,5701,5801,5901,6001,6101,6201,6301,6401,6501,6601,6701,6801,6901,7001,7101,7201,7301,7401,7501,7601,7701,7801,7901,8001,8101,8201,8301,8401,8501,8601,8701,8801,8901,9001,9101,9201,9301,9401,9501,9601,9701,9801,9901,10001,10101,10201,10301,10401,10501],\"y\":[96.42857142857143,61.51419558359621,46.91011235955056,41.778020179983635,38.710407239819006,36.28924833491912,34.55906821963394,33.30410638608797,32.15608465608465,30.738880918220946,29.32051562158619,28.533359652585865,28.02673696102429,27.418927277547052,26.649704530531842,26.023501234937505,25.22201244668205,24.693796918214144,23.902645758915057,23.06343009109942,22.87620700878811,22.440042772035234,22.101238869531553,21.579189686924494,21.1047971455002,20.72884341189298,20.493676050591596,20.36935166994106,20.32860457155897,19.84103835496573,19.595024383348647,19.41111570817818,19.25520115618593,19.112661685811144,18.924296396136196,18.999108620909208,19.08490953298178,18.909641907353578,18.854138004830475,18.803212366402995,18.694229625223084,18.504862824793147,18.290404755165582,18.138735692708476,18.116120555144946,17.97668698534916,17.784348099113007,17.75802367047393,17.774319463224224,17.727100919742973,17.58157294456015,17.697717458359037,17.57829517401617,17.446064415510765,17.331905881257708,17.24534111537489,17.119417826794432,17.139500864400016,17.14116381675703,17.06788115376274,16.965875211805333,16.844462282684468,16.873558397986997,16.77629544095511,16.73777687047055,16.683831101956745,16.56655074296554,16.403529138611564,16.46950729298266,16.366919868930594,16.31310245682585,16.298925905698162,16.344448064878172,16.219879786683787,16.127385395394693,16.177959297657697,16.177959297657697,16.177959297657697,16.177959297657697,16.177959297657697,16.177959297657697,16.177959297657697,16.177959297657697,16.177959297657697,16.177959297657697,16.177959297657697,16.177959297657697,16.177959297657697,16.177959297657697,16.177959297657697,16.177959297657697,16.177959297657697,16.177959297657697,16.177959297657697,16.177959297657697,16.177959297657697,16.177959297657697,16.177959297657697,16.177959297657697,16.177959297657697,16.177959297657697,16.177959297657697,16.177959297657697,16.177959297657697,16.177959297657697,16.177959297657697],\"type\":\"scatter\"},{\"mode\":\"lines+markers\",\"name\":\"Overall Lexical Diversity (Unprocessed)\",\"x\":[1,101,201,301,401,501,601,701,801,901,1001,1101,1201,1301,1401,1501,1601,1701,1801,1901,2001,2101,2201,2301,2401,2501,2601,2701,2801,2901,3001,3101,3201,3301,3401,3501,3601,3701,3801,3901,4001,4101,4201,4301,4401,4501,4601,4701,4801,4901,5001,5101,5201,5301,5401,5501,5601,5701,5801,5901,6001,6101,6201,6301,6401,6501,6601,6701,6801,6901,7001,7101,7201,7301,7401,7501,7601,7701,7801,7901,8001,8101,8201,8301,8401,8501,8601,8701,8801,8901,9001,9101,9201,9301,9401,9501,9601,9701,9801,9901,10001,10101,10201,10301,10401,10501],\"y\":[84.0,31.963688485427618,23.106880138468195,20.112517580872012,18.08045018757816,16.70162558993183,15.746592553110487,14.92775817298089,14.248005279260903,13.5256549036588,12.756129919905657,12.11081679621347,11.870175147339587,11.521849099186738,11.100281568117826,10.85881887687846,10.448175813321809,10.162341440707552,9.787984920995642,9.387327108403655,9.103897320592093,8.854864573951629,8.607809146442133,8.361446728385376,8.15870512242752,8.003222053163878,7.867909732508495,7.703190798781605,7.5512439864725405,7.360475754803293,7.238281019093219,7.114132379248658,6.996620124113476,6.862679045450258,6.781287379891427,6.7077097447257925,6.627660647634419,6.562341627421168,6.490872210953347,6.416691505216095,6.339485033719422,6.256555246477268,6.156751652502361,6.104967564978884,6.056942319420519,6.003012489278467,5.930128947018036,5.875071702442412,5.7989830141728875,5.74666009795114,5.668391527684492,5.620512820512821,5.561044331009752,5.505464358797931,5.452435174845466,5.396010065634161,5.358054525033184,5.32736411144027,5.291074800886773,5.264609941738749,5.22927753296893,5.179037230258478,5.107922587043092,5.058623658207693,5.010966889009074,4.9627864995635,4.899045800146133,4.834974968312078,4.77639945793808,4.715461402101602,4.671474625278341,4.633257671400443,4.600192212181609,4.544646372283816,4.508219839175697,4.479482414821309,4.479482414821309,4.479482414821309,4.479482414821309,4.479482414821309,4.479482414821309,4.479482414821309,4.479482414821309,4.479482414821309,4.479482414821309,4.479482414821309,4.479482414821309,4.479482414821309,4.479482414821309,4.479482414821309,4.479482414821309,4.479482414821309,4.479482414821309,4.479482414821309,4.479482414821309,4.479482414821309,4.479482414821309,4.479482414821309,4.479482414821309,4.479482414821309,4.479482414821309,4.479482414821309,4.479482414821309,4.479482414821309,4.479482414821309,4.479482414821309],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Overall Lexical Diversity over Batch Size Increments\"},\"xaxis\":{\"title\":{\"text\":\"Number of Sentences\"}},\"yaxis\":{\"title\":{\"text\":\"Lexical Diversity (%)\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('75217271-a37c-474f-993d-7e48d619c5d6');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------- Text Metrics for Emma (Unprocessed) ---------\n",
            "Total Words: 161983\n",
            "Total Sentences: 10567\n",
            "Overall Lexical Diversity: 4.48%\n",
            "Average Lexical Diversity of Sentences: 94.43%\n",
            "Top Ten Most Frequent Words: to, the, and, of, i, a, it, her, was, she\n",
            "Highest Frequency Word: 'to' (Frequency: 5239)\n",
            "\n",
            "--------- Text Metrics for Emma (Processed) ---------\n",
            "Total Words: 57300\n",
            "Total Sentences: 1\n",
            "Overall Lexical Diversity: 16.22%\n",
            "Average Lexical Diversity of Sentences: 16.22%\n",
            "Top Ten Most Frequent Words: made, like, frank, ever, young, churchill, two, though, indeed, better\n",
            "Highest Frequency Word: 'made' (Frequency: 198)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}