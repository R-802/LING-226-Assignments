{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "PzlOvwvazKpi",
        "VschkUGr0ico"
      ],
      "toc_visible": true,
      "mount_file_id": "1GcRPo2mLq-Htzt-muxNzzm7VjPrNW0uq",
      "authorship_tag": "ABX9TyNLeLb1UmGVx2lWWx7IcgrD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/R-802/LING-226-Assignments/blob/main/Assignment_Two.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LING226 2023 T3 Assignment Two\n",
        "- Shemaiah Rangitaawa\n",
        "- `300601546`\n",
        "\n",
        "### **Research Questions**\n",
        "\n",
        "> How do linguistic features, including distributional and syntactic measures, contribute to the construction of the descriptive language in bestselling mystery novels compared to bestselling science fiction novels?\n",
        "   \n",
        "This question aims to delve into the linguistic features chosen for constructing the profiles. By focusing on distributional and syntactic measures, we can uncover the nuances in language use specific to each genre. The rationale behind this question is to understand the fine-grained details of how authors employ language in mystery and science fiction, contributing to the overall descriptive elements in their respective genres.\n",
        "\n",
        "> In what ways do the results of the linguistic analysis provide insights into the role of setting and atmosphere in genre-specific storytelling within bestselling mystery and science fiction novels?\n",
        "   \n",
        "This question addresses the broader narrative context by linking linguistic analysis results to the role of setting and atmosphere in storytelling. It aims to connect the linguistic profiles with the overarching theme of how descriptive language influences the creation of setting and atmosphere in mystery and science fiction. By exploring this connection, the study seeks to extract meaningful insights into the distinct storytelling approaches employed by each genre.\n",
        "\n",
        "### **Predictions**\n",
        "**Descriptive Detail**:\n",
        "   - Mystery novels will probably use more precise and plot-driven descriptions.\n",
        "   - Science fiction novels are anticipated to have broader, more imaginative descriptions.\n",
        "\n",
        "**Lexical Choices**:\n",
        "   - Mystery novels might use language that evokes suspense and mystery.\n",
        "   - Science fiction novels are expected to include technical and futuristic terminology.\n",
        "\n",
        "**Atmosphere and Mood**:\n",
        "   - Descriptions in mystery novels are predicted to create a tense, suspenseful mood.\n",
        "   - In science fiction, the language is likely to evoke wonder and exploration."
      ],
      "metadata": {
        "id": "CvQePg-5PZXn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Preprocessing Pipeline for Text Analysis**\n",
        "**Text Cleaning**: This step involves converting all text to lowercase, removing punctuation, and eliminating numbers. This standardization ensures uniformity and relevance in the analysis.\n",
        "\n",
        "**Removing Stop Words**: Common words like \"the\", \"is\", and \"in\" are removed using NLTK's predefined list of stop words. These words are irrelevant to the overall meaning in most analysis contexts.\n",
        "\n",
        "**Custom TF-IDF Vectorization**: Extends standard TF-IDF by applying thresholds to filter out words based on their frequency across the books. This approach allows us to focus on words that are uniquely significant to the novel being analyzed."
      ],
      "metadata": {
        "id": "ocudlLMpWWpS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "esOq4kb4OIbL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ea2cc4e-1f4b-4fd5-bd09-edda85868ae9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    # Lowercasing\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove punctuations and numbers\n",
        "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
        "\n",
        "    # Remove single character words\n",
        "    text = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', text)\n",
        "\n",
        "    # Remove multiple spaces\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "Z4AB-_uUWWHm"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stopwords(text):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    word_tokens = word_tokenize(text)\n",
        "    filtered_text = [word for word in word_tokens if word not in stop_words]\n",
        "    return ' '.join(filtered_text)"
      ],
      "metadata": {
        "id": "DFugnUjMWsE1"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tfidf_filter(corpus, lower_percentile=10, upper_percentile=90):\n",
        "    # Vectorize the corpus\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    X = vectorizer.fit_transform(corpus)\n",
        "\n",
        "    # Calculate the inverse document frequency\n",
        "    idf = vectorizer.idf_\n",
        "    idf_dict = dict(zip(vectorizer.get_feature_names_out(), idf))\n",
        "\n",
        "    # Determine lower and upper thresholds based on percentiles\n",
        "    lower_threshold = np.percentile(list(idf_dict.values()), lower_percentile)\n",
        "    upper_threshold = np.percentile(list(idf_dict.values()), upper_percentile)\n",
        "\n",
        "    # Filter out words outside the middle range of TF-IDF scores\n",
        "    middle_tfidf_words = {word: score for word, score in idf_dict.items()\n",
        "                          if lower_threshold <= score <= upper_threshold}\n",
        "\n",
        "    # Re-create the corpus without extreme TF-IDF words\n",
        "    cleaned_corpus = []\n",
        "    for document in corpus:\n",
        "        tokens = document.split()\n",
        "        filtered_tokens = [token for token in tokens if token in middle_tfidf_words]\n",
        "        cleaned_corpus.append(' '.join(filtered_tokens))\n",
        "\n",
        "    return cleaned_corpus"
      ],
      "metadata": {
        "id": "zxqHleucWcVd"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(corpus, lower_percentile=10, upper_percentile=90):\n",
        "    # Clean and normalize each document in the corpus\n",
        "    cleaned_corpus = [clean_text(doc) for doc in corpus]\n",
        "\n",
        "    # Remove stop words\n",
        "    no_stopwords_corpus = [remove_stopwords(doc) for doc in cleaned_corpus]\n",
        "\n",
        "    # Remove words outside the middle range of TF-IDF scores\n",
        "    final_corpus = tfidf_filter(no_stopwords_corpus, lower_percentile, upper_percentile)\n",
        "    return final_corpus"
      ],
      "metadata": {
        "id": "LX54coTFJTo2"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Data and Corpus Selection**\n",
        "\n",
        "> To import the corpus into Colab please download the texts from [this link](https://drive.google.com/drive/folders/15A7y8NRaJv2LRBB6zDm4043G1f9sMTWD) and add under 'My Drive' in Google Drive.\n",
        "\n",
        "### Selection Rationale\n",
        "I have chosen ten texts for each genre, following these criteria to ensure a comprehensive and meaningful analysis:\n",
        "\n",
        "- **Genre Representation**: Each book is a well-recognized example of its genre, ensuring a clear distinction between the mystery and science fiction categories. This selection helps maintain genre purity in the analysis, enabling a focused examination of genre-specific linguistic characteristics. Well-known works in each genre are chosen to represent common patterns and themes that are emblematic of their respective genres.\n",
        "\n",
        "- **Narrative Styles**: The selection includes a range of narrative styles, from first-person accounts to omniscient narrators, offering diverse syntactic structures. This variety allows for a more nuanced exploration of how different narrative perspectives influence the use of descriptive language. By including a mix of narrative styles, the analysis can uncover how the choice of narrator affects the portrayal of setting and atmosphere.\n",
        "\n",
        "- **Thematic Variety**: The books cover various sub-genres and themes, providing a rich linguistic variety for analysis. For instance, the mystery genre includes classic whodunits, psychological thrillers, and detective stories, while the science fiction genre encompasses hard sci-fi, space operas, and dystopian narratives. This thematic diversity ensures that the analysis captures a broad spectrum of language usage, avoiding biases that might arise from focusing on a narrow thematic range.\n",
        "\n",
        "- **Publication Era**: The texts span different publication eras, reflecting the evolution of language and narrative techniques over time. This temporal spread helps in understanding how descriptive language in both genres has evolved and how historical and cultural contexts influence storytelling.\n",
        "\n",
        "- **Authorial Background**: The authors of these texts come from varied backgrounds, contributing to diverse perspectives and styles in their writing. This inclusion enriches the linguistic analysis by introducing different cultural and individual influences in the use of language.\n",
        "\n",
        "- **Critical and Popular Reception**: The texts are a mix of critically acclaimed works and popular bestsellers. This ensures that the analysis encompasses both literary quality and mass appeal, reflecting a balance between artistic merit and accessibility to a broader audience."
      ],
      "metadata": {
        "id": "N9jRiG3agEDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "EzxCAN6GgDdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def read_text_files(directory_path):\n",
        "    \"\"\"Reads all text files in a directory and returns a set of their contents.\"\"\"\n",
        "    text_contents = set()\n",
        "    for filename in os.listdir(directory_path):\n",
        "        if filename.endswith('.txt'):\n",
        "            file_path = os.path.join(directory_path, filename)\n",
        "            with open(file_path, 'r', encoding='utf-8') as file:\n",
        "                full_text = file.read()\n",
        "                text_contents.add(full_text)\n",
        "    return text_contents"
      ],
      "metadata": {
        "id": "jhDkr8B_dXP8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_titles(text_set):\n",
        "    \"\"\"Returns a list of the first lines of each text in a set.\"\"\"\n",
        "    titles = []\n",
        "    for text in text_set:\n",
        "        first_line = text.split('\\n', 1)[0]\n",
        "        titles.append(first_line)\n",
        "    return titles\n",
        "\n",
        "mystery_path = '/content/drive/My Drive/LING226 Assignment 2 Corpus/Mystery/'\n",
        "scifi_path = '/content/drive/My Drive/LING226 Assignment 2 Corpus/SciFi/'\n",
        "\n",
        "mystery_texts = read_text_files(mystery_path)\n",
        "mystery_titles = get_titles(mystery_texts)\n",
        "print(\"Mystery Novels:\")\n",
        "for title in mystery_titles:\n",
        "    print(title)\n",
        "\n",
        "scifi_texts = read_text_files(scifi_path)\n",
        "scifi_titles = get_titles(scifi_texts)\n",
        "print(\"\\nScifi Novels:\")\n",
        "for title in scifi_titles:\n",
        "    print(title)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXK-X5sSdjyk",
        "outputId": "a0a9b5bb-4031-4afc-faff-3c8e297754e6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mystery Novels:\n",
            "[Sharp Objects by Gillian Flynn 2006]\n",
            "[The Name of the Rose by Umberto Eco 1980]\n",
            "[The Girl on the Train by Paula Hawkins 2015]\n",
            "[Before I Go to Sleep by S.J Watson 2008]\n",
            "[The Girl With The Dragon Tattoo by Stieg Larsson 2005]\n",
            "[In the Woods by Tana French 2007]\n",
            "[And Then There Were None by Agatha Christie 1939]\n",
            "[The Woman in the Window by A.J. Finn 2018]\n",
            "[The Da Vinci Code by Dan Brown 2003]\n",
            "[Murder on the Orient Express by Agatha Christie 1934]\n",
            "\n",
            "Scifi Novels:\n",
            "[Neuromancer by William Gibson 1984]\n",
            "[Brave New World by Aldous Huxley 1931]\n",
            "[The War of the Worlds by H. G. Wells 1898]\n",
            "[DUNE by Frank Herbert 1965]\n",
            "[The Hitchhiker’s Guide to the Galaxy by Douglas Adams 1979]\n",
            "[Snow Crash by Neal Stephenson 1992]\n",
            "[The Martian by Andy Weir 2011]\n",
            "[Children of Time by Adrain Tchaokovsky 2015]\n",
            "[Nineteen Eighty-Four by George Orwell 1949]\n",
            "[Fahrenheit 451 by Ray Bradbury 1953]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature Extraction and Lexical Profile Generation**\n",
        "\n",
        "## Lexicon Information\n",
        "\n",
        "**Lexical Diversity and Vocabulary Richness**: Exploring lexical diversity and vocabulary richness in texts offer insights into how authors in different genres, like mystery and science fiction, utilize language. This feature measures the variety and sophistication of the vocabulary, shedding light on the linguistic intricacies that each genre employs to create its unique narrative worlds and tones. In doing so, it allows us to determine the thematic emphases of each genre, as mystery novels might lean towards a more nuanced, reality-anchored lexicon, whereas science fiction could delve into more innovative and speculative terminologies, each contributing to their distinctive atmospheres.\n",
        "\n",
        "**Sentiment Analysis**: By evaluating the emotional tone, such as the prevalent suspense in mysteries or the awe in science fiction, this feature helps in dissecting how authors manipulate emotions to shape the reader's experience. It is particularly telling in understanding the intended emotional journey and the atmospheric creation within the narrative settings of each genre, revealing how authors use sentiment to immerse readers in the world they have created.\n",
        "\n",
        "**Frequency of Adjectives and Adverbs**: Since adjectives and adverbs are often used to describe settings and characters, analyzing their frequency can reveal how visually or sensorially detailed each genre is. This can inform how each genre crafts its atmosphere and setting.\n",
        "\n",
        "## Distributional Information\n",
        "\n",
        "**Collocates**:\n",
        "Collocate analysis delves into the contextual associations of key words within different genres, such as mystery and science fiction. It uncovers the thematic nuances and settings unique to each genre by examining how specific words cluster with others, providing insights into the distinct narrative techniques and atmospheres each genre employs.\n",
        "\n",
        "**Part of Speech (POS) Analysis**:\n",
        "POS analysis offers a look into the syntactic composition of different literary genres. By comparing how various parts of speech are used in mystery versus science fiction texts, we can infer stylistic and narrative preferences, such as the prevalence of descriptive language versus action-oriented dialogue, each contributing to the creation of unique settings and atmospheres.\n",
        "\n",
        "**Bigram Analysis**:\n",
        "Bigram analysis reveals the characteristic phrase structures in different genres, highlighting how specific word pairings contribute to the thematic and atmospheric construction in mystery and science fiction novels. This analysis is instrumental in understanding the narrative style and world-building techniques of each genre."
      ],
      "metadata": {
        "id": "QNXdb2GK9dCB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Extraction Function Definitions**"
      ],
      "metadata": {
        "id": "KN1TeV-IAO0U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import pos_tag\n",
        "from nltk import bigrams, word_tokenize\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from nltk.collocations import BigramCollocationFinder\n",
        "from nltk.metrics import BigramAssocMeasures\n",
        "import numpy as np\n",
        "from textblob import TextBlob\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from collections import Counter\n",
        "\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
        "nltk.download('vader_lexicon', quiet=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0ekB1_sQGwD",
        "outputId": "f8d759be-05fb-4439-86c9-8d5c9686592a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lexical Diversity**\n",
        "   - **Implementation**:"
      ],
      "metadata": {
        "id": "0jvhQf3-Wven"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lexical_diversity(text):\n",
        "    \"\"\"Calculate lexical diversity as the ratio of unique words to total words.\"\"\"\n",
        "    tokens = word_tokenize(text)\n",
        "    return len(set(tokens)) / len(tokens) if tokens else 0\n",
        "\n",
        "def calculate_average_lexical_diversity(texts):\n",
        "    \"\"\"Calculate the average lexical diversity for a set of texts.\"\"\"\n",
        "    diversities = [lexical_diversity(text) for text in texts]\n",
        "    return np.mean(diversities)"
      ],
      "metadata": {
        "id": "dETSaASqWvtu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sentiment Analysis**\n",
        "   - **Implementation**:"
      ],
      "metadata": {
        "id": "yu1F40RvM4Oo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"Using CPU\")\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "5v1vq_PR8QyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def segment_text(text, max_length=512):\n",
        "    # Split the text by newline characters and remove empty paragraphs\n",
        "    paragraphs = [para for para in text.split('\\n') if para.strip() != '']\n",
        "    segments = []\n",
        "    current_segment = \"\"\n",
        "\n",
        "    for paragraph in paragraphs:\n",
        "        if len(current_segment) + len(paragraph) <= max_length:\n",
        "            current_segment += \" \" + paragraph if current_segment else paragraph\n",
        "        else:\n",
        "            if current_segment:\n",
        "                segments.append(current_segment)\n",
        "            current_segment = paragraph\n",
        "\n",
        "    # Add the last segment if it contains any text\n",
        "    if current_segment:\n",
        "        segments.append(current_segment)\n",
        "\n",
        "    return segments\n",
        "\n",
        "\n",
        "def sentiment_analysis(text):\n",
        "    segments = segment_text(text)\n",
        "    sentiments = []\n",
        "\n",
        "    for segment in segments:\n",
        "        inputs = tokenizer(segment, return_tensors=\"pt\", truncation=True, max_length=512, padding=True)\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "        with torch.no_grad():  # Disable gradient calculation for inference\n",
        "            outputs = model(**inputs)\n",
        "            prediction = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "            sentiment_score = prediction[:,1].item() - prediction[:,0].item()  # Positive - Negative\n",
        "            sentiments.append(sentiment_score)\n",
        "\n",
        "    return sentiments"
      ],
      "metadata": {
        "id": "Dyq4j5_SNpvw"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Frequency of Adjectives and Adverbs**\n",
        "   - **Implementation**: The text is tokenized and POS-tagged to count adjectives and adverbs. This count reflects the extent of descriptive language used."
      ],
      "metadata": {
        "id": "zGB6gAb0M6LF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_adj_adv_freq_combined(texts):\n",
        "    total_adjectives = 0\n",
        "    total_adverbs = 0\n",
        "    total_texts = len(texts)\n",
        "\n",
        "    for text in texts:\n",
        "        words = word_tokenize(text)\n",
        "        tagged = pos_tag(words)\n",
        "\n",
        "        for word, tag in tagged:\n",
        "            if tag.startswith(\"JJ\"):\n",
        "                total_adjectives += 1\n",
        "            elif tag.startswith(\"RB\"):\n",
        "                total_adverbs += 1\n",
        "\n",
        "    # Calculating the mean for adjectives and adverbs\n",
        "    avg_adjectives = total_adjectives / total_texts if total_texts > 0 else 0\n",
        "    avg_adverbs = total_adverbs / total_texts if total_texts > 0 else 0\n",
        "\n",
        "    return {\"average_adjectives\": avg_adjectives, \"average_adverbs\": avg_adverbs}"
      ],
      "metadata": {
        "id": "KwFvyBIbANoo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Collocates**\n",
        "   - **Implementation**: NLTK's BigramCollocationFinder is used to find words that frequently appear near a target word, giving insight into word associations."
      ],
      "metadata": {
        "id": "zN18iYnlM8CB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_collocates(text, word):\n",
        "    tokens = word_tokenize(text)\n",
        "    bigram_measures = BigramAssocMeasures()\n",
        "    finder = BigramCollocationFinder.from_words(tokens)\n",
        "    word_filter = lambda *w: word not in w\n",
        "    finder.apply_ngram_filter(word_filter)\n",
        "    return finder.nbest(bigram_measures.likelihood_ratio, 10)"
      ],
      "metadata": {
        "id": "ccMz8Eyu76jo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Part of Speech (POS) Analysis**\n",
        "   - **Implementation**: The text is POS-tagged to analyze the frequency of different parts of speech. This approach gives a broad overview of the syntactic structure of the text."
      ],
      "metadata": {
        "id": "SojJY0oCM-YY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pos_frequency(text):\n",
        "    words = word_tokenize(text)\n",
        "    tagged = pos_tag(words)\n",
        "    pos_counts = {}\n",
        "    for word, tag in tagged:\n",
        "        pos_counts[tag] = pos_counts.get(tag, 0) + 1\n",
        "    return pos_counts"
      ],
      "metadata": {
        "id": "z8OkMzpvM-_Z"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Top 10 Bigrams**\n",
        "   - **Implementation**: The text is analyzed for bigrams to identify common word pairings."
      ],
      "metadata": {
        "id": "9xMG2fhFM-Wg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_bigrams(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    bigram_counts = Counter(bigrams(tokens))\n",
        "    return bigram_counts.most_common(10)"
      ],
      "metadata": {
        "id": "uI-t54kf77kF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Preprocessing and Feature Extraction**"
      ],
      "metadata": {
        "id": "tdIG5B4UAV_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mystery_processed_texts = preprocess(mystery_texts)\n",
        "scifi_processed_texts = preprocess(scifi_texts)"
      ],
      "metadata": {
        "id": "qKeCr-8KRZXN"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply feature extraction functions for each genre\n",
        "mystery_profile = {\n",
        "    \"Lexical Diversity\": calculate_average_lexical_diversity(mystery_processed_texts),\n",
        "    \"Sentiment\": sentiment_analysis(text) for text in mystery_texts,\n",
        "    \"Adjective and Adverb Frequency\": mean_adj_adv_freq_combined(mystery_processed_texts),\n",
        "    \"Top 10 Most Common Bigrams\": get_bigrams(\" \".join(mystery_processed_texts))\n",
        "}\n",
        "\n",
        "scifi_profile = {\n",
        "    \"Lexical Diversity\":  calculate_average_lexical_diversity(scifi_processed_texts),\n",
        "    \"Sentiment\": np.mean([sentiment_analysis(text) for text in scifi_texts]),\n",
        "    \"Adjective and Adverb Frequency\": mean_adj_adv_freq_combined(scifi_processed_texts),\n",
        "    \"Top 10 Most Common Bigrams\": get_bigrams(\" \".join(scifi_processed_texts))\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "V_07uqBROX7M",
        "outputId": "41120fde-5d24-4f66-f277-7903dec8581f"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-c6885ea3c5bf>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Sentiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;34m\"Sentiment\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msentiment_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmystery_texts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;34m\"Adjective and Adverb Frequency\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmean_adj_adv_freq_combined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmystery_processed_texts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;34m\"Top 10 Most Common Bigrams\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_bigrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmystery_processed_texts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-45-c6885ea3c5bf>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Sentiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;34m\"Sentiment\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msentiment_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmystery_texts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;34m\"Adjective and Adverb Frequency\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmean_adj_adv_freq_combined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmystery_processed_texts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;34m\"Top 10 Most Common Bigrams\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_bigrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmystery_processed_texts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-42-a18435ebcb45>\u001b[0m in \u001b[0;36msentiment_analysis\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msegment\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msegments\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0msentiment_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# difference between positive and negative scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1562\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1564\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1565\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1566\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1011\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         )\n\u001b[0;32m-> 1013\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1014\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    605\u001b[0m                 )\n\u001b[1;32m    606\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    608\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    537\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[1;32m    540\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pytorch_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_and_print_profile(profile, genre_name):\n",
        "    print(f\"{genre_name} Genre Profile:\\n\")\n",
        "    for feature, value in profile.items():\n",
        "        print(f\"{feature}:\")\n",
        "\n",
        "        if isinstance(value, (int, float)):\n",
        "            # For numerical values (e.g., Lexical Diversity, Sentiment)\n",
        "            print(f\"  {value:.4f}\\n\")\n",
        "\n",
        "        elif isinstance(value, dict):\n",
        "            # For dictionary values (e.g., Adjective and Adverb Frequency)\n",
        "            for sub_feature, sub_value in value.items():\n",
        "                print(f\"  {sub_feature}: {sub_value:.2f}\")\n",
        "            print()  # Add a newline for better separation\n",
        "\n",
        "        elif isinstance(value, list):\n",
        "            for item in value[:10]:\n",
        "                if isinstance(item, tuple) and all(isinstance(elem, str) for elem in item[0]):\n",
        "                    # For bigrams, which are tuples of strings\n",
        "                    bigram_str = ' '.join(item[0])\n",
        "                    count = item[1]\n",
        "                    print(f\"  {bigram_str}: {count}\")\n",
        "            print()  # Add a newline for better separation\n",
        "\n",
        "    print(\"\\n---------------------------------------\\n\")\n",
        "\n",
        "format_and_print_profile(mystery_profile, \"Mystery\")\n",
        "format_and_print_profile(scifi_profile, \"SciFi\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrkPV9NuRyTS",
        "outputId": "d30a1b1c-4ee3-413e-8c06-4ee322d90bb8"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mystery Genre Profile:\n",
            "\n",
            "Lexical Diversity:\n",
            "  0.3510\n",
            "\n",
            "Sentiment:\n",
            "  0.0039\n",
            "\n",
            "Adjective and Adverb Frequency:\n",
            "  average_adjectives: 3730.20\n",
            "  average_adverbs: 855.30\n",
            "\n",
            "Top 10 Most Common Bigrams:\n",
            "  langdon sophie: 148\n",
            "  da vinci: 125\n",
            "  holy grail: 123\n",
            "  martin vanger: 120\n",
            "  sophie langdon: 111\n",
            "  philip lombard: 84\n",
            "  opus dei: 82\n",
            "  justice wargrave: 81\n",
            "  mr justice: 80\n",
            "  henrik vanger: 77\n",
            "\n",
            "\n",
            "---------------------------------------\n",
            "\n",
            "SciFi Genre Profile:\n",
            "\n",
            "Lexical Diversity:\n",
            "  0.3576\n",
            "\n",
            "Sentiment:\n",
            "  -0.0067\n",
            "\n",
            "Adjective and Adverb Frequency:\n",
            "  average_adjectives: 3813.00\n",
            "  average_adverbs: 931.90\n",
            "\n",
            "Top 10 Most Common Bigrams:\n",
            "  feyd rautha: 201\n",
            "  muad dib: 199\n",
            "  bene gesserit: 187\n",
            "  uncle enzo: 132\n",
            "  log entry: 119\n",
            "  entry sol: 119\n",
            "  ebooks ebook: 117\n",
            "  ebook com: 117\n",
            "  da id: 109\n",
            "  duke leto: 61\n",
            "\n",
            "\n",
            "---------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Analysis**"
      ],
      "metadata": {
        "id": "ii0Mbl2b0NZb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iG51S1BH5FLX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}